# DeepSeek-OCR Projekt - Ãœberblick

**Ziel:** DeepSeek-OCR auf **gedruckten deutschen Dokumenten** evaluieren

## Quick Facts

- **Anwendung:** OCR fÃ¼r gedruckte Texte (PDFs, Scans, Screenshots)
- **Modell:** DeepSeek-OCR (3B Parameter, 6.7 GB)
- **Hardware:** RTX 4080 (16 GB VRAM) âœ… Perfekt!
- **Setup:** Lokal, Python 3.11.9, CUDA 13.0
- **Status:** Ready for testing

## Projekt-Scope

### âœ… IN SCOPE (Was wir testen)
- Gedruckte Dokumente (PDF, PNG, JPG)
- Formeln und Tabellen
- Mehrsprachige Texte (Deutsch, Englisch)
- Wissenschaftliche Papers
- Screenshots von Webseiten

### âŒ OUT OF SCOPE (Was wir NICHT testen)
- Handschrifterkennung (HTR)
- Historische Dokumente (Kurrentschrift)
- Handgeschriebene Notizen

**Grund:** DeepSeek-OCR ist fÃ¼r gedruckte Texte optimiert, nicht fÃ¼r Handschrift.

## Projektstruktur

```
deepseek-ocr/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ printed_docs/          # Test-Dokumente (gedruckt)
â”‚   â”‚   â”œâ”€â”€ README.md          # Anleitung fÃ¼r Test-Daten
â”‚   â”‚   â”œâ”€â”€ sample_01.png      # Beispiel-Dokument
â”‚   â”‚   â””â”€â”€ ground_truth/      # Manuelle Transkriptionen
â”‚   â”‚       â””â”€â”€ sample_01.txt
â”‚   â””â”€â”€ _archive/              # Alte Handschrift-Daten (ignoriert)
â”œâ”€â”€ knowledge/                 # Dokumentation
â”‚   â”œâ”€â”€ README.md             # Dieser Ãœberblick
â”‚   â”œâ”€â”€ TECHNICAL.md          # Technische Details
â”‚   â”œâ”€â”€ LEARNINGS.md          # Lessons Learned
â”‚   â””â”€â”€ TEST_RESULTS.md       # Test-Ergebnisse
â”œâ”€â”€ results/                  # OCR Outputs
â”‚   â””â”€â”€ batch_TIMESTAMP/      # Batch-Ergebnisse
â”œâ”€â”€ venv/                     # Python Environment
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ test_ocr_simple.py       # Single-Image Test
â”œâ”€â”€ test_ocr_batch.py        # Batch Processing
â””â”€â”€ compare_results.py       # Evaluation (CER/WER)
```

## Workflow

### 1. Test-Dokumente vorbereiten
```bash
# Kopiere gedruckte Dokumente nach:
data/printed_docs/sample_01.png
data/printed_docs/sample_02.pdf
...

# Erstelle Ground Truth (manuelle Transkription):
data/printed_docs/ground_truth/sample_01.txt
data/printed_docs/ground_truth/sample_02.txt
...
```

### 2. Batch-Processing durchfÃ¼hren
```bash
python test_ocr_batch.py data/printed_docs/
```

**Output:**
```
results/batch_20251027_120000/
â”œâ”€â”€ sample_01.txt          # OCR Ergebnis
â”œâ”€â”€ sample_02.txt
â”œâ”€â”€ summary.json           # Statistiken
â””â”€â”€ temp/                  # Intermediate files
```

### 3. Evaluation
```bash
python compare_results.py results/batch_20251027_120000/
```

**Metriken:**
- **CER (Character Error Rate):** Zeichenfehler-Rate
- **WER (Word Error Rate):** Wortfehler-Rate
- **Precision/Recall/F1:** Genauigkeit

**Output:** `results/batch_TIMESTAMP/evaluation.json`

## Aktueller Status

| Task | Status | Details |
|------|--------|---------|
| Environment Setup | âœ… | Python 3.11.9, PyTorch 2.6.0+cu118 |
| Model Download | âœ… | DeepSeek-OCR cached (~7 GB) |
| Hardware Verification | âœ… | RTX 4080, 16 GB VRAM, CUDA 13.0 |
| Single Image Test | âœ… | test_ocr_simple.py funktioniert |
| Batch Processing | âœ… | test_ocr_batch.py erstellt |
| Evaluation Framework | âœ… | compare_results.py mit CER/WER |
| **Test Data** | â³ | **BenÃ¶tigt gedruckte Dokumente!** |
| OCR DurchfÃ¼hrung | â¹ï¸ | Wartet auf Test-Daten |
| Quantitative Analyse | â¹ï¸ | Wartet auf OCR-Ergebnisse |

## NÃ¤chste Schritte

### 1. Test-Dokumente sammeln (TODO)

**Einfacher Start:** Wikipedia-Screenshots
```python
# Beispiel: Screenshot erstellen
from selenium import webdriver
driver = webdriver.Chrome()
driver.get("https://de.wikipedia.org/wiki/KÃ¼nstliche_Intelligenz")
driver.save_screenshot("data/printed_docs/wikipedia_ki.png")
```

**Empfohlene Quellen:**
- Wikipedia-Artikel (Deutsch)
- arXiv Papers (PDF â†’ PNG)
- Gescannte BÃ¼cher (Google Books, Archive.org)
- Screenshots von Nachrichtenseiten

**BenÃ¶tigt:** 5-10 Dokumente fÃ¼r erste Evaluation

### 2. Ground Truth erstellen
FÃ¼r jedes Dokument: Manuell abtippen â†’ `.txt` File

### 3. Batch-Processing
```bash
python test_ocr_batch.py data/printed_docs/
```

### 4. Evaluation
```bash
python compare_results.py results/batch_TIMESTAMP/
```

## Performance (RTX 4080)

```
Model Loading:     ~5 min (first time, cached danach)
Inference:         ~10-30 sec/image (abhÃ¤ngig von GrÃ¶ÃŸe)
Throughput:        ~120-360 pages/hour
VRAM Usage:        ~10 GB wÃ¤hrend Inferenz
Memory:            ~6 GB RAM
```

## Use Cases

### âœ… Ideal fÃ¼r DeepSeek-OCR:
- ğŸ“„ PDFs digitalisieren
- ğŸ§® LaTeX-Formeln extrahieren
- ğŸ“Š Tabellen â†’ Markdown konvertieren
- ğŸ“š Gescannte BÃ¼cher transkribieren
- ğŸŒ Mehrsprachige Dokumente

### âŒ Nicht geeignet:
- âœï¸ Handschrifterkennung
- ğŸ›ï¸ Historische Dokumente (Fraktur, Kurrentschrift)
- ğŸ“ Handgeschriebene Notizen

## Links

- **Model:** https://huggingface.co/deepseek-ai/DeepSeek-OCR
- **GitHub:** https://github.com/deepseek-ai/DeepSeek-OCR
- **Hardware-Check:** `nvidia-smi`

---

**Last Updated:** 2025-10-27
**Status:** Ready - benÃ¶tigt nur Test-Dokumente
**Hardware:** RTX 4080 (16 GB VRAM) âœ…
