# DeepSeek-OCR Evaluation Framework

> AI-powered OCR pipeline for printed documents with METS metadata support and interactive visualization

[![Live Demo](https://img.shields.io/badge/demo-live-success)](https://chpollin.github.io/deepseek-ocr/)
[![Python](https://img.shields.io/badge/python-3.11%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/pytorch-2.6.0-red)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-research-orange)](LICENSE)

---

## ğŸ¯ Overview

Complete OCR evaluation pipeline for processing **printed documents** (METS archives, PDFs) using DeepSeek-OCR:

- ğŸ“„ **METS Support** - Process digital archive documents with XML metadata
- ğŸ“‘ **PDF Processing** - Direct PDF-to-OCR conversion (tested with 595 pages)
- ğŸ” **Artifact Filtering** - Automatic removal of color cards, measurements, reference marks
- ğŸ“Š **Interactive Viewer** - Side-by-side image/text comparison with zoom
- ğŸŒ **GitHub Pages** - Lightweight sample deployment (5-10 pages per document)
- ğŸ“ˆ **Detailed Reports** - Statistics, CER metrics, full transcriptions

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/chpollin/deepseek-ocr.git
cd deepseek-ocr

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: ./venv/Scripts/activate (Windows)

# Install dependencies
pip install -r requirements.txt
```

### Process Documents

```bash
# METS document
python scripts/test_ocr_mets.py data/o_szd.151/

# PDF
python scripts/test_ocr_pdf.py data/document.pdf

# Create samples for GitHub Pages
python scripts/create_samples.py

# Generate interactive viewer
python scripts/generate_viewer_simple.py

# View locally
cd docs && python -m http.server 8000
# Open http://localhost:8000/
```

---

## ğŸ“Š Results

| Document | Lang | Pages | CER | Status |
|----------|------|-------|-----|--------|
| **o:szd.151** | DE | 3 | ~2-3% | âœ… Complete |
| **o:szd.196** | FR | 9 | N/A | âœ… Complete |
| **DTS_Flechte.pdf** | DE | 595 | TBD | ğŸ”„ Processing |

**Live Demo:** [https://chpollin.github.io/deepseek-ocr/](https://chpollin.github.io/deepseek-ocr/)

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Model** | [DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR) (3B params, BF16) |
| **Framework** | PyTorch 2.6.0, Transformers 4.46.3 |
| **PDF** | PyMuPDF (fitz) |
| **CUDA** | 11.8 / 13.0 |
| **Frontend** | Vanilla HTML/CSS/JS (no frameworks) |

**Hardware:** RTX 4080 (16 GB VRAM) recommended

---

## ğŸ“‚ Project Structure

```
deepseek-ocr/
â”œâ”€â”€ docs/                         # ğŸŒ GitHub Pages Website
â”‚   â”œâ”€â”€ index.html               # Main viewer page
â”‚   â”œâ”€â”€ style.css                # Viewer styles
â”‚   â”œâ”€â”€ viewer.js                # Viewer logic + data
â”‚   â””â”€â”€ samples/                 # Sample images
â”œâ”€â”€ scripts/                      # ğŸ”§ Python Scripts
â”‚   â”œâ”€â”€ README.md                # Scripts documentation
â”‚   â”œâ”€â”€ test_ocr_mets.py         # METS document processor
â”‚   â”œâ”€â”€ test_ocr_pdf.py          # PDF processor
â”‚   â”œâ”€â”€ filter_artifacts.py      # Artifact detection & removal
â”‚   â”œâ”€â”€ create_samples.py        # Sample generator for GitHub Pages
â”‚   â”œâ”€â”€ generate_viewer_simple.py # Viewer generator
â”‚   â””â”€â”€ clean_ocr_results.py     # Apply filters to results
â”œâ”€â”€ knowledge/                    # ğŸ“š Obsidian Vault Documentation
â”‚   â”œâ”€â”€ 00-Index.md              # Overview & quick navigation
â”‚   â”œâ”€â”€ 01-Quick-Start.md        # Installation & usage
â”‚   â”œâ”€â”€ 02-Architecture.md       # System design & data flow
â”‚   â”œâ”€â”€ 03-Results.md            # Evaluation & metrics
â”‚   â””â”€â”€ 04-Learnings.md          # Best practices & tips
â”œâ”€â”€ samples/                      # ğŸ¨ Deployment Samples
â”‚   â”œâ”€â”€ images/                  # Sample images (12 total)
â”‚   â”œâ”€â”€ *_sample.json            # Viewer data
â”‚   â”œâ”€â”€ *_full.json              # Complete data
â”‚   â”œâ”€â”€ *_transcription.txt      # Full transcriptions
â”‚   â””â”€â”€ *_report.md              # Statistical reports
â”œâ”€â”€ data/                         # ğŸ“‚ Input Documents
â”‚   â”œâ”€â”€ o_szd.151/               # METS (German, 3 pages)
â”‚   â”œâ”€â”€ o_szd.196/               # METS (French, 9 pages)
â”‚   â””â”€â”€ DTS_Flechte.pdf          # PDF (595 pages)
â”œâ”€â”€ results/                      # ğŸ’¾ OCR Outputs
â”‚   â”œâ”€â”€ mets_*/                  # METS processing results
â”‚   â””â”€â”€ pdf_*/                   # PDF processing results
â””â”€â”€ requirements.txt             # Python dependencies
```

---

## âœ¨ Features

### OCR Processing
- **METS XML Parsing** - Extract metadata (title, author, URN, language)
- **PDF Conversion** - High-quality 300 DPI image extraction
- **Batch Processing** - Sequential page-by-page processing
- **Progress Tracking** - Real-time character count and timing

### Artifact Filtering
- **Pattern-Based Detection** - Keywords, regex, structural analysis
- **Effectiveness** - 47-99% noise reduction on test documents
- **Categories** - Color references, measurements, scale markers

### Interactive Viewer
- **Side-by-Side Comparison** - Original image vs OCR text
- **Zoom & Pan** - Mousewheel zoom, drag to navigate
- **Thumbnail Navigation** - Quick page selection
- **Keyboard Shortcuts** - â†â†’ (pages), +- (zoom), C (copy)
- **Export Functions** - Download text, download image

### GitHub Pages Support
- **Smart Sampling** - 5-10 evenly distributed representative pages
- **Lightweight** - < 10 MB total (vs 1+ GB for full data)
- **Full Access** - Complete transcriptions and data available as downloads

---

## ğŸ“– Documentation

Comprehensive documentation in Obsidian-compatible Markdown:

- **[00-Index.md](knowledge/00-Index.md)** - Project overview & navigation
- **[01-Quick-Start.md](knowledge/01-Quick-Start.md)** - Installation & usage examples
- **[02-Architecture.md](knowledge/02-Architecture.md)** - System design & components
- **[03-Results.md](knowledge/03-Results.md)** - Performance metrics & evaluation
- **[04-Learnings.md](knowledge/04-Learnings.md)** - Best practices & troubleshooting
- **[scripts/README.md](scripts/README.md)** - Scripts documentation & workflow

**View in Obsidian:** Open `knowledge/` folder as vault

---

## ğŸ¯ Use Cases

### âœ… Ideal For
- ğŸ“„ Digitalizing printed documents
- ğŸ“Š Extracting text from scanned PDFs
- ğŸ›ï¸ Processing digital archives (METS format)
- ğŸŒ Multi-language documents (DE, EN, FR, ...)
- ğŸ”¢ Documents with formulas and tables

### âŒ Not Suitable For
- âœï¸ Handwriting recognition
- ğŸ›ï¸ Historical scripts (Kurrent, Fraktur)
- ğŸ“ Handwritten notes
- ğŸ¨ Complex artistic layouts

---

## ğŸ”¬ Performance

| Metric | Value | Hardware |
|--------|-------|----------|
| **Model Load** | ~30-45s | First run (cached after) |
| **OCR per Page** | ~15-20s | RTX 4080 |
| **Throughput** | 120-360 pages/hour | Varies by content |
| **VRAM Usage** | ~10 GB | During inference |
| **Accuracy (DE)** | ~97-98% | CER on test docs |

---

## ğŸ¤ Contributing

This is a research project. Contributions, issues, and feature requests are welcome!

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request

---

## ğŸ“ License

Research use only. See [LICENSE](LICENSE) for details.

---

## ğŸ”— Links

- **Live Demo:** https://chpollin.github.io/deepseek-ocr/
- **Model:** https://huggingface.co/deepseek-ai/DeepSeek-OCR
- **Documentation:** [docs/](docs/)
- **Issues:** https://github.com/chpollin/deepseek-ocr/issues

---

## ğŸ™ Acknowledgments

- **DeepSeek AI** - For the excellent OCR model
- **Stefan Zweig Digital** - For METS test data
- **PyMuPDF** - For reliable PDF processing

---

**Last Updated:** 2025-10-27
**Status:** Active Development
**Maintainer:** Research Team
